{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b24b37a",
   "metadata": {},
   "source": [
    "# PPO\n",
    "\n",
    "We will use Ray libiray to implement the PPO model, with code modified from the official website of Ray.\n",
    "\n",
    "Code reference: https://docs.ray.io/en/latest/rllib/rllib-training.html#basic-python-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8117377",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if needed: !pip install -U \"ray[rllib]\"\n",
    "import numpy as np\n",
    "from random import random\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "import time\n",
    "import torch, torchvision, cv2\n",
    "\n",
    "import gym\n",
    "import ray\n",
    "from ray import tune\n",
    "import ray.rllib.agents.ppo as ppo\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce5bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "   device = torch.device('cuda')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011698cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomize(seed_rng=12345, seed_np=42, seed_torch=42):\n",
    "    os.environ['PYTHONHASHSEED'] = '0'\n",
    "    rng = np.random.default_rng(12345)\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize ray\n",
    "ray.init(ignore_reinit_error=True)\n",
    "#set config\n",
    "config_ppo = ppo.DEFAULT_CONFIG.copy()\n",
    "config_ppo[\"num_gpus\"] = 0\n",
    "config_ppo[\"num_workers\"] = 4\n",
    "config_ppo[\"framework\"] = 'torch'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c793ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate trainer\n",
    "trainer_ppo = ppo.PPOTrainer(config=config_ppo, env=\"Breakout-v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99722a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df146f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PPO training\n",
    "#initialize for random seeds/states\n",
    "randomize()\n",
    "\n",
    "avg_rewards_ppo = []\n",
    "\n",
    "for i in range(2):\n",
    "    # Perform one iteration of training the policy with PPO\n",
    "    result_ppo = trainer_ppo.train()\n",
    "    #print(pretty_print(result_ppo))\n",
    "    print(result_ppo['episode_reward_mean'])\n",
    "    avg_rewards_ppo.append(result_ppo['episode_reward_mean'])\n",
    "\n",
    "    if (i+1) % 100 == 0:\n",
    "        checkpoint_ppo = trainer_ppo.save()\n",
    "        print(\"checkpoint saved at\", checkpoint_ppo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc28ef58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tune hyperparameters\n",
    "stop=tune.stopper.MaximumIterationStopper(max_iter=50)\n",
    "config_ppo_tune={\n",
    "        \"env\": \"Breakout-v0\",\n",
    "        \"num_gpus\": 0,\n",
    "        \"num_workers\": 4,\n",
    "        \"framework\": \"torch\",\n",
    "        \"lr\": tune.grid_search([5e-5, 1e-5, 5e-6, 1e-6]),\n",
    "    }\n",
    "\n",
    "#initialize for random seeds/states\n",
    "randomize()\n",
    "\n",
    "# tune.run() allows setting a custom log directory (other than ``~/ray-results``)\n",
    "# and automatically saving the trained agent\n",
    "analysis = tune.run(\n",
    "    ppo.PPOTrainer,\n",
    "    config=config_ppo_tune,\n",
    "    stop=stop,\n",
    "    checkpoint_at_end=True)\n",
    "\n",
    "# list of lists: one list per checkpoint; each checkpoint list contains\n",
    "# 1st the path, 2nd the metric value\n",
    "checkpoints = analysis.get_trial_checkpoints_paths(\n",
    "    trial=analysis.get_best_trial(\"episode_reward_mean\"),\n",
    "    metric=\"episode_reward_mean\")\n",
    "\n",
    "# if there are multiple trials, select a specific trial or automatically\n",
    "# choose the best one according to a given metric\n",
    "last_checkpoint = analysis.get_last_checkpoint(\n",
    "    metric=\"episode_reward_mean\", mode=\"max\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22df57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_checkpoint[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed3c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load DQN rewards\n",
    "with open(\"avg_rewards1_restore.txt\", \"r\") as file:\n",
    "    avg_rewards1_restore = eval(file.readline())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b116244",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([i+200 for i in range(800)], avg_rewards1_restore, label='DQN rainbow excl dueling')\n",
    "plt.plot(last_checkpoint[1], label='PPO')\n",
    "\n",
    "plt.xlabel('Count of Iterations')\n",
    "plt.ylabel('Reward per Episode')\n",
    "\n",
    "plt.title('Average Reward in Breakout')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef42bf6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
